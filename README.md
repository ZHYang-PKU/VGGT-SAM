# Multi-View SAM: Multi-View Image Segmentation by Combining SAM and VGGT

## ğŸ“‹ Project Overview

**Multi-View** SAM is a framework for multi-view image segmentation based on pre-trained **SAM (Segment Anything Model)** and **VGGT (Visual Geometry Grounded Transformer)**. This project enables simultaneous semantic segmentation across multiple viewpoints using a single point prompt from the first image.

## ğŸ¯ Core Task

Given a set of multi-view images, achieve:

-Accurate segmentation of the first image using a point prompt

-Consistent segmentation results across all viewpoints

-High-quality segmentation masks generated simultaneously for all views

## ğŸ—ï¸ Architecture

This project explores two different method combinations:

### Method 1: SAM + VGGT (See SAM_VGGT.py)

**Pipeline:**
```text
First image (point prompt) â†’ SAM segmentation â†’ Select highest confidence mask â†’ VGGT track to other views
```

**Characteristics:**

    -âœ… Advantages: Stable segmentation results, accurate point tracking
    
    -âŒ Disadvantages:
    
        High GPU memory usage (~20GB for large masks)
        
        Slow inference speed
        
        Potential mask discontinuity issues

### Method 2: VGGT + SAM (See VGGT_SAM.py)

**Pipeline:**
```text
First image (point prompt) â†’ VGGT track to other views â†’ Separate SAM segmentation for each view
```

**Characteristics:**

    âœ… Advantages:  Low GPU memory usage, fast inference
    
    âŒ Disadvantages:  Segmentation consistency may be compromised
